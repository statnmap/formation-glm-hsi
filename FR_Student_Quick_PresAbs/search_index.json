[
["1-preface.html", "Formation aux GLM et aux modèles de distribution d’espèces 1 Préface", " Formation aux GLM et aux modèles de distribution d’espèces Sébastien Rochette 14 mars, 2018 1 Préface La version d’origine de cette formation a été créée par Olivier Le Pape et Étienne Rivot à Agrocampus Ouest (Rennes, France). Depuis mon doctorat dans leur équipe, je mets à jour constamment cette formation au gré de ma recherche et de l’évolution du logiciel R. # Generated with R and rmarkdown: Roadmap version - Students "],
["2-presentation-de-letude.html", "2 Présentation de l’étude 2.1 Contexte 2.2 Objectifs 2.3 Données 2.4 Covariables 2.5 Ajuster un modèle de distribution d’espèces 2.6 Exploration des données", " 2 Présentation de l’étude Le contexte et les objectifs de votre étude définissent le type de modélisation que vous allez mettre en place sur votre jeu de données. Ici, nous utilisons les modèles linéaires généralisés pour produire une carte de distribution moyenne de la nourricerie de soles communes de la baie de Vilaine. 2.1 Contexte Les zones côtières et les estuaires sont des habitats halieutiques essentiels Zones à forte production Nourriceries Zones restreintes avec de fortes densités (Fig. 2.1) Figure 2.1: Plaice box (Rijnsdorp et al.) Pression anthropique élevée Perte de surface disponibles (Fig. 2.2a) Qualité des habitats alterée (Fig. 2.2b) Impact sur le renouvellement des populations Jeune stades = Gouleau d’étranglement La taille et la qualité des nourriceries côtières influent sur la production de juvéniles Figure 2.2: (a) L’estuaire de la Seine. (b) Niveau de contamination chimique le long des côtes françaises (Ifremer, 2011) 2.2 Objectifs Déterminer les facteurs ayant une influence sur la distribution des poissons plats (Solea solea) en Baie de Vilaine et cartographier la distribution moyenne des densités. Cartographier les habitats potentiels nécessite: Connaissance des habitats de juvéniles Campagnes d’échantillonnage dans la zone d’étude Connaissance des covariables environnementales ayant potentiellement de l’influence Cartes exhaustives des covariables environnementales Une approche statistique en deux étapes Modèle statistique reliant les densités aux covariables Prédire les habitats potentiels 2.3 Données Campagne standardisée de chalut à perche dans la baie de Vilaine (Fig. 2.3) 1984 – 2010 En autumne Juvéniles de l’année (Âge 0) Nb individus / 1000m2 Figure 2.3: (a) L’estuaire de la Vilaine. (b) Chalut à perche. (c) Situation des stations d’échantillonnage. 2.4 Covariables Bathymétrie (Fig. 2.4a) MNT à 1000m de résolution Projection Mercator Structure sédimentainre (Fig. 2.4b) Fichier shape de polygones Coordonnées géographiques Zones biologiques (Fig. 2.4c) Combinaison bathymétrie, sédiment, habitat Fichier shape de polygones Coordonnées géographiques Figure 2.4: Covariables en baie de Vilaine. (a) Structure sédimentaire, (b) Bathymétrie et (c) Zones biologiques. 2.5 Ajuster un modèle de distribution d’espèces Croiser les données avec les cartes de covariables Utiliser un modèle linéaire Utiliser les cartes des covariables pour la prédiction (Fig. 2.5) Une prédiction pour chaque cellule d’un raster Figure 2.5: Procédure pour un modèle de distribution d’espèce 2.6 Exploration des données Prenez le temps d’explorer vos données avant toutes analyses Explorer les données et les covariables Explorer le plan d’échantillonnage Explorer les liens potentiels entre les densités et les covariables Explorer les futurs paramètres de modélisation (interactions, distributions) Souvenez-vous toujours des objectifs de votre étude ! Question : Que recherchons-nous dans cette exploration ? "],
["3-preparation.html", "3 Préparation 3.1 Structure des dossiers 3.2 Débutons avec R 3.3 Sous-modèle Binomial", " 3 Préparation 3.1 Structure des dossiers Il convient de toujours conserver les fichiers originaux : les reprojections entraînent toujours quelques pertes, mieux vaut revenir aux originaux lorsque c’est possible. L’arborescence de votre dossier de travail est la suivante : 01_Original_data DEPARTEMENTS Sedim_GDG_wgs84 bathy_GDG_1000_merc (and co) Data_Vilaine_solea.csv 02_Outputs 03_Figures 04_Functions 3.2 Débutons avec R Créer un projet Rstudio dans le dossier principal de travail. Ouvrez le script R : “Quick_PresAbs_Student.R” Lister les différents sous-dossier de travail au début de votre script R # Define working directories --------------------------------------------------- WD &lt;- here() # Folder of original files origWD &lt;- here(&quot;01_Original_data&quot;) # Folder for outputs saveWD &lt;- here(&quot;02_Outputs&quot;) # Folder where to save outputs from R figWD &lt;- here(&quot;03_Figures&quot;) # Folder where complementary functions are stored funcWD &lt;- here(&quot;04_Functions&quot;) 3.3 Sous-modèle Binomial 3.3.1 Étapes La procédure à adopter avec le sous-groupe de données est la même qu’avec le jeu de données complet. Créer les observations de présence-absences à partir du jeu de données Explorer ce nouveau jeu de données Utiliser une distribution binomiale Tester les covariables, les interactions, les fonctions de lien, les critères de qualité Choisir le meilleur modèle 3.3.2 Exploration 3.3.3 Ajuster un modèle binomial avec une fonction de lien Le choix de la distribution pour un modèle de présence-absence est simple, c’est un modèle binomial. Cepedant, un modèle est généralement ajusté sur la base de résidus Gaussiens. Pour ajuster un modèle binomial, les données doivent être transformées de telle sorte qu’on puisse ajuster un modèle linéaire Gaussien classique dessus. Pour cela, nous utilisons une fonction de lien. La fonction de lien classique d’un modèle binomial est la fonction logit, mais ce n’est pas la seule. Vous pouvez tester cloglog, probit ou cauchit. 3.3.4 Qualité d’ajustement d’un modèle binomial Une mesure couramment utilisée pour la qualité d’ajustement d’un modèle binomial est “l’aire sous la courbe” (AUC : Area Under the Curve). Un objectif des modèles binomiaux étant de prédire un succès ou un échec, et non pas seulement une probabilité de succès, on peut vouloir définir un seuil (intuitivement 0.5 par exemple) qui transforme la probabilité de présence en présence ou absence. L’AUC est en quelque sorte une probabilité de classer correctement les présences et absences. Une définition plus complète serait : La probabililité moyenne pour qu’une observation=1 et une observation=0 choisies de manière aléatoire dans le jeu de données montrent une probabilité de présence prédite supérieure pour l’observation=1 par rapport à celle de l’observation=0 Ainsi, \\(AUC = 1\\) montrerait un modèle “parfait”, mais \\(AUC = 0.5\\) montrerait un modèle plus mauvais que le hasard. Figure 3.1: (a) Prédiction vs Observations. (b) Courbe ROC d’un modèle binomial 3.3.5 Choix du meilleur seuil Le modèle sélectionné sur la base de l’AIC est-il toujours le meilleur modèle avec l’AUC sur les données de validation ? "]
]
