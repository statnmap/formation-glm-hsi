[
["1-preface.html", "Formation aux GLM et aux modèles de distribution d’espèces 1 Préface", " Formation aux GLM et aux modèles de distribution d’espèces Sébastien Rochette 15 février, 2018 1 Préface La version d’origine de cette formation a été créée par Olivier Le Pape et Étienne Rivot à Agrocampus Ouest (Rennes, France). Depuis mon doctorat dans leur équipe, je mets à jour constamment cette formation au gré de ma recherche et de l’évolution du logiciel R. # Generated with R and rmarkdown: Roadmap version - Students "],
["2-presentation-de-letude.html", "2 Présentation de l’étude 2.1 Contexte 2.2 Objectifs 2.3 Données 2.4 Covariables 2.5 Ajuster un modèle de distribution d’espèces 2.6 Exploration des données", " 2 Présentation de l’étude Le contexte et les objectifs de votre étude définissent le type de modélisation que vous allez mettre en place sur votre jeu de données. Ici, nous utilisons les modèles linéaires généralisés pour produire une carte de distribution moyenne de la nourricerie de soles communes de la baie de Vilaine. 2.1 Contexte Les zones côtières et les estuaires sont des habitats halieutiques essentiels Zones à forte production Nourriceries Zones restreintes avec de fortes densités (Fig. 2.1) Figure 2.1: Plaice box (Rijnsdorp et al.) Pression anthropique élevée Perte de surface disponibles (Fig. 2.2a) Qualité des habitats alterée (Fig. 2.2b) Impact sur le renouvellement des populations Jeune stades = Gouleau d’étranglement La taille et la qualité des nourriceries côtières influent sur la production de juvéniles Figure 2.2: (a) L’estuaire de la Seine. (b) Niveau de contamination chimique le long des côtes françaises (Ifremer, 2011) 2.2 Objectifs Déterminer les facteurs ayant une influence sur la distribution des poissons plats (Solea solea) en Baie de Vilaine et cartographier la distribution moyenne des densités. Cartographier les habitats potentiels nécessite: Connaissance des habitats de juvéniles Campagnes d’échantillonnage dans la zone d’étude Connaissance des covariables environnementales ayant potentiellement de l’influence Cartes exhaustives des covariables environnementales Une approche statistique en deux étapes Modèle statistique reliant les densités aux covariables Prédire les habitats potentiels 2.3 Données Campagne standardisée de chalut à perche dans la baie de Vilaine (Fig. 2.3) 1984 – 2010 En autumne Juvéniles de l’année (Âge 0) Nb individus / 1000m2 Figure 2.3: (a) L’estuaire de la Vilaine. (b) Chalut à perche. (c) Situation des stations d’échantillonnage. 2.4 Covariables Bathymétrie (Fig. 2.4a) MNT à 1000m de résolution Projection Mercator Structure sédimentainre (Fig. 2.4b) Fichier shape de polygones Coordonnées géographiques Zones biologiques (Fig. 2.4c) Combinaison bathymétrie, sédiment, habitat Fichier shape de polygones Coordonnées géographiques Figure 2.4: Covariables en baie de Vilaine. (a) Structure sédimentaire, (b) Bathymétrie et (c) Zones biologiques. 2.5 Ajuster un modèle de distribution d’espèces Croiser les données avec les cartes de covariables Utiliser un modèle linéaire Utiliser les cartes des covariables pour la prédiction (Fig. 2.5) Une prédiction pour chaque cellule d’un raster Figure 2.5: Procédure pour un modèle de distribution d’espèce 2.6 Exploration des données Prenez le temps d’explorer vos données avant toutes analyses Explorer les données et les covariables Explorer le plan d’échantillonnage Explorer les liens potentiels entre les densités et les covariables Explorer les futurs paramètres de modélisation (interactions, distributions) Souvenez-vous toujours des objectifs de votre étude ! Question : Que recherchons-nous dans cette exploration ? "],
["3-preparation.html", "3 Préparation 3.1 Structure des dossiers 3.2 Débutons avec R", " 3 Préparation 3.1 Structure des dossiers Il convient de toujours conserver les fichiers originaux : les reprojections entraînent toujours quelques pertes, mieux vaut revenir aux originaux lorsque c’est possible. L’arborescence de votre dossier de travail est la suivante : 01_Original_data DEPARTEMENTS Sedim_GDG_wgs84 bathy_GDG_1000_merc (and co) Data_Vilaine_solea.csv 02_Outputs 03_Figures 04_Functions 3.2 Débutons avec R Créer un projet Rstudio dans le dossier principal de travail. Ouvrez le script R : “Quick_AllDataModel_Student.R” Lister les différents sous-dossier de travail au début de votre script R # Define working directories --------------------------------------------------- WD &lt;- here() # Folder of original files origWD &lt;- here(&quot;01_Original_data&quot;) # Folder for outputs saveWD &lt;- here(&quot;02_Outputs&quot;) # Folder where to save outputs from R figWD &lt;- here(&quot;03_Figures&quot;) # Folder where complementary functions are stored funcWD &lt;- here(&quot;04_Functions&quot;) "],
["4-exploration-des-donnees-1.html", "4 Exploration des données 4.1 Étapes 4.2 Liste des différentes étapes", " 4 Exploration des données 4.1 Étapes Souvenez-vous : Définissez ce que vous cherchez, à quelles questions vous souhaiteriez répondre ! Explorer la répartition du plan d’échantillonnage en fonction des covariables environementales Explorer les données d’observation au regard des covariables environnementales pour détecter de potentielles corrélations Explorer les interactions entre les effets des covariables sur les observations Explorer les lois de distribution possibles (gaussian, log-normal, …) des observations en fonctions des combinaisons de covariables Les scripts qui sont fournis ne sont que des exemples, ils ne sont en aucun cas les meilleures solutions ! Faîtes vos propres tests ! 4.2 Liste des différentes étapes Lire le jeu de données spatialisé (Fig. 4.1) Figure 4.1: Répartition des stations d’échantillonnage Ajouter une nouvelle covariable : la bathymétrie divisée en classes &quot; &lt; 5 m“,”5-10 m“,”10-20 m“,”20-50 m&quot; Explorer la répartition des observations en fonctions des covariables Centrer l’analyse sur l’année, la bathymétrie et le sédiment Que remarquez-vous ? Explorer les covariables ayant potentiellement des effets sur les densités Quelles covariables pourraient avoir une influence ? Les modèles statistiques que nous allons utiliser peuvent se résumer de cette façon : \\[Density = Covar1 + Covar2 + Noise\\] Comme vous le savez, on chercher toujours à savoir si les données sont gaussienne pour pouvoir procéder à l’analyse statistique. Si elles ne sont pas gaussienne, nous devons définir le type de distribution pour pouvoir utiliser une transformation de données. Explorer la distribution des données Quelle est la distribution la plus intéressante ? Figure 4.2: (ref:RFigDistribCap) Explorer les interactions potentielles entre les covariables Qu’en pensez-vous ? "],
["5-modelisation.html", "5 Modélisation 5.1 Étapes 5.2 Interpréter les sorties de modèles 5.3 Trouver le meilleur modèle 5.4 Prédictions du modèle", " 5 Modélisation 5.1 Étapes Souvenez-vous: Définissez ce que vous cherchez, à quelles questions vous souhaiteriez répondre ! Tester les différentes formes de modèles au regard des combinaisons de covariables et des formes de distributions des résidus Comparer les modèles à l’aide des outils statistiques à disposition (AIC, anova, …), de la validation croisée mais aussi de la connaissance du jeu de données et des questions ciblées Analyser les résidus des modèles. Analyser leur distribution et s’assurer que les hypothèses de construction sont vérifiées. C’est seulement lorsque les hypothèses sur la distribution des résidus sont vérifiées, que les covariables et les interactions sélectionnées peuvent commencer à être interprétées… Les scripts qui sont fournis ne sont que des exemples, ils ne sont en aucun cas les meilleures solutions ! Faîtes vos propres tests ! 5.2 Interpréter les sorties de modèles Lorsque vous ajustez un modèle linéaire (lm ou glm), vous pouvez utiliser différents tests statistiques et visuels qui répondent à différentes questions. Votre question principale pourrait être : “Est-ce que mes covariables ont un effet sur mes observations ?”. En réalité, ce n’est pas exactement la question à laquelle va répondre votre modèle. Ce serait plutôt “Est-ce que les covariables que j’ai utilisées expliquent une part de la variabilité de mes observations ?” Pour que vous puissiez interpréter les différentes sorties de modèles, dans ce document, nous allons regarder le modèle suivant : \\[lm(Density ~ Bathy + Sedim, data = dataset)\\] Ce modèle n’est pas forcément le meilleur modèle à choisir ! 5.2.1 Summary(lm) Cette fonction montre un tableau de tests de significativité (Table 5.1). Ce sont des tests de Student. Ils testent si la valeur estimée pour un effet est ou non significativement différente de zéro. Ainsi, si une covariable a un effet non significativement différent de l’effet nul, il est probablement inutile de la conserver dans le modèle. Table 5.1: Exemple d’une sortie de summary(lm) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 173.4 14.27 12.152 0.000 Bathy 14.5 1.71 8.472 0.000 Sedim2sand -19.5 19.07 -1.020 0.308 Sedim3coarse -39.4 57.21 -0.689 0.491 5.2.2 Analyse de résidus Une hypothèse de construction d’un modèle linéaire est l’homoscédasticité, aussi appelée homogénéité de la variance. Cela signifie que la variance de la réponse y est la même quelque soit la valeur du prédicteur x. Dans un modèle Gaussien classique ajustant x à y ainsi: \\(y = a.x + b + \\epsilon\\), la variable \\(\\epsilon\\) représente les résidus du modèle. Ils sont supposés être centrés sur zéro et avec une variance Gaussienne, leur distribution suivant ainsi la loi Gaussienne \\(\\epsilon \\sim N(0, \\sigma)\\) Figure 5.1: Figures de diagnostic d’un modèle linéaire permettant de vérifier les hypothèses de construction. 5.2.3 Analyse de variance La question à laquelle répond une anova (avec un test du Chi-2) est : Est-ce que la covariable ajoutée augmente significativitement la vraisemblance du modèle (ou a réduit la déviance résiduelle), comparé au modèle précédent, sans cette covariable ? Table 5.2: Exemple d’une sortie de anova(lm) Df Sum Sq Mean Sq F value Pr(&gt;F) Bathy 1 1607692 1607692 71.983 0.000 Sedim 2 32206 16103 0.721 0.487 Residuals 397 8866764 22334 NA NA 5.2.4 Critères d’Akaike (AIC) et Bayesian (BIC) L’AIC et le BIC sont des critères de qualité d’ajustement pénalisés par le nombre de paramètres estimés. La description (traduite) de ces fonctions dans R est : Function générique calculant “Le Critère d’Information” d’Akaike pour un ou plusieurs modèles ajustés pour lesquels une “log-vraisemblance” peut être obtenue, en utilisant la formule \\(IC = -2*log-likelihood + k*npar\\), où npar represente le nombre de paramètres estimés, et k = 2 pour l’AIC classique, ou k = log(n) (n étant le nombre d’observations) pour le BIC ou SBC (Schwarz’s Bayesian criterion). 5.3 Trouver le meilleur modèle La fonction lm n’est utilisée que pour des modèles avec une distribution Gaussienne des résidus. Pour tester d’autres types de distributions, il faut utiliser glm, avec un paramètre pour la famille de distribution (family). Vous pouvez utiliser des distributions qui autorisent une plus grande queue de distribution que la loi Normale. Parmis les familles disponibles, vous pouvez tester poisson, quasipoisson, Gamma, Log-gaussian. Quel est le meilleur modèle au regard des différents critères évoqués ? 5.4 Prédictions du modèle Lorsque vous êtes satisfaits du modèle sélectionné, vous pouvez faire des prédictions Utiliser le fichier csv fourni pour voir l’effet des covariables sélectionnées (Fig. 5.2) Figure 5.2: Prédictions du meilleur GLM sélectionné "]
]
